"""Define the abstract dataset generator that generate the dataset used to assess RAGs' performances.

The Dataset is made of EvalSample. An EvalSample contains all the information necessary for evaluation.
"""

from __future__ import annotations

from abc import abstractmethod
from typing import TYPE_CHECKING, Optional, Self, TypeVar, overload

from rago.dataset import QADataset, QADatasetLoader

if TYPE_CHECKING:
    from rago.model.wrapper.llm_agent import LLMAgent

from pydantic import Field
from pydantic.dataclasses import dataclass

from rago.data_objects import Document, EvalSample, PromptTemplate
from rago.model.configs.llm_config.base import LLMConfig  # noqa: TC001
from rago.model.wrapper.llm_agent import LangchainLLMAgent
from rago.model.wrapper.llm_agent.llm_agent_factory import LLMAgentFactory
from rago.prompts import DEFAULT_DATASET_GENERATION_PROMPT


@dataclass
class DatasetGeneratorConfig:
    """Configuration of the dataset generator."""

    llm: Optional[LLMConfig] = None
    prompt: str = Field(default=DEFAULT_DATASET_GENERATION_PROMPT)


DatasetGeneratorType = TypeVar("DatasetGeneratorType", bound="BaseDatasetGenerator")


class BaseDatasetGenerator[DataType, DatasetType: QADataset]:
    """Abstract class that defines the generator that generate datasets.

    A generated dataset contains list of eval samples each sample contains a query and optionally:
    a context, an explanation and a reference_answer.
    Example Usage:
    The elements of the dataset generated by the DatasetGenerator can be used by the evaluator or the RAG.
    In Rago, the optimizer uses the dataset generator to generate the dataset
    and pass its elements to the RAG and evaluator.
    However the dataset Generator can also be used on its own if one just need to generate a synthetic dataset.
    """

    def __init__(
        self,
        generator: Optional[LLMAgent] = None,
        generation_prompt: str = DEFAULT_DATASET_GENERATION_PROMPT,
    ) -> None:
        """Create a Dataset Generator.

        :param generator: LLM used as generator by the Dataset Generator, defaults to None
        :type generator: Optional[LLMAgent], optional
        :param generation_prompt: Prompt used by the LLM to generate eval samples,
        defaults to DEFAULT_DATASET_GENERATION_PROMPT.
        :type generation_prompt: str, optional
        """
        super().__init__()
        self.generator = generator if generator is not None else LangchainLLMAgent.make_from_backend()
        self.generation_prompt = PromptTemplate(generation_prompt)

    @abstractmethod
    def generate_dataset(self, seed_data: Optional[DataType] = None) -> DatasetType:
        """Generate the synthetic dataset.

        :param seed_data: Data used by the generator to create synthetic data, defaults to None.
        :type documents: Optional[DatasetType], optional
        :return: The generated dataset.
        :rtype: DatasetType
        """

    @overload
    def generate_and_save_dataset(
        self,
        name: str,
        dataset_path: None = None,
        cache_dir: Optional[str] = None,
        seed_data: Optional[DataType] = None,
    ) -> DatasetType: ...

    @overload
    def generate_and_save_dataset(
        self,
        name: None,
        dataset_path: str,
        cache_dir: None,
        seed_data: Optional[DataType] = None,
    ) -> DatasetType: ...

    def generate_and_save_dataset(
        self,
        name: Optional[str] = None,
        dataset_path: Optional[str] = None,
        cache_dir: Optional[str] = None,
        seed_data: Optional[DataType] = None,
    ) -> DatasetType:
        """Generate the dataset and save it to the specified path.

        :param documents: Original Dataset used by the generator to create a synthetic one, defaults to None.
        :type documents: Optional[DatasetType], optional
        :param path_dataset: The path to save the dataset to.
        :type path_dataset: str
        :return: The generated dataset.
        :rtype: DatasetType
        """
        dataset_path = QADatasetLoader.get_dataset_path(name, dataset_path, cache_dir)
        generated_dataset = self.generate_dataset(seed_data)
        generated_dataset.save_to_disk(generated_dataset, dataset_path)
        return generated_dataset

    @abstractmethod
    def parse_generation(self, generation: str, document: Document) -> list[EvalSample]:
        """Parse the output of the generator model to get new eval samples.

        :parameter generation: The generation output from the generator to parse.
        :type generation: str
        :param document: The document the questions are generated on.
        :type document: Document
        :return: The new eval samples obtained by parsing the generator's output.
        :rtype: EvalSample
        """

    @classmethod
    def make(
        cls,
        config: Optional[DatasetGeneratorConfig] = None,
    ) -> Self:
        """Make a dataset Generator from its configuration parameters and repository.

        :param config: The configuration parameters of the dataset generator to make.
        :type config: DatasetGeneratorConfig
        :return: The built dataset generator.
        :rtype: BaseDatasetGenerator
        """
        config = config if config is not None else DatasetGeneratorConfig()
        llm = LLMAgentFactory.make(config.llm) if config.llm is not None else LangchainLLMAgent.make_from_backend()

        dataset_generator = cls(
            generator=llm,
            generation_prompt=config.prompt,
        )
        return dataset_generator
